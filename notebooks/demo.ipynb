{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "363f001d",
   "metadata": {},
   "source": [
    "# ü§ñ Intelligent Database & CSV Chatbot with RAG\n",
    "\n",
    "This notebook demonstrates the capabilities of our chatbot with Retrieval-Augmented Generation (RAG) enhancement.\n",
    "\n",
    "## Features:\n",
    "- **Local AI Models**: Uses HuggingFace transformers\n",
    "- **RAG Enhancement**: Improved context-aware responses\n",
    "- **Database Integration**: Query and analyze SQL databases\n",
    "- **CSV Analysis**: Business intelligence from CSV data\n",
    "- **Completely Local**: No API keys required"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b46b768",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setup and imports\n",
    "import sys\n",
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from datetime import datetime\n",
    "\n",
    "# Add project root to path\n",
    "project_root = os.path.dirname(os.path.dirname(os.path.abspath('__file__')))\n",
    "sys.path.append(project_root)\n",
    "\n",
    "print(\"üöÄ Setting up Chatbot with RAG...\")\n",
    "print(f\"Project root: {project_root}\")\n",
    "print(f\"Python version: {sys.version}\")\n",
    "print(f\"Pandas version: {pd.__version__}\")\n",
    "print(f\"NumPy version: {np.__version__}\")\n",
    "\n",
    "# Check available dependencies\n",
    "dependencies = {}\n",
    "\n",
    "try:\n",
    "    import transformers\n",
    "    dependencies['transformers'] = transformers.__version__\n",
    "    print(f\"‚úÖ Transformers: {transformers.__version__}\")\n",
    "except ImportError:\n",
    "    dependencies['transformers'] = None\n",
    "    print(\"‚ùå Transformers not available\")\n",
    "\n",
    "try:\n",
    "    import sentence_transformers\n",
    "    dependencies['sentence_transformers'] = sentence_transformers.__version__\n",
    "    print(f\"‚úÖ Sentence Transformers: {sentence_transformers.__version__}\")\n",
    "except ImportError:\n",
    "    dependencies['sentence_transformers'] = None\n",
    "    print(\"‚ùå Sentence Transformers not available\")\n",
    "\n",
    "try:\n",
    "    import chromadb\n",
    "    dependencies['chromadb'] = chromadb.__version__\n",
    "    print(f\"‚úÖ ChromaDB: {chromadb.__version__}\")\n",
    "except ImportError:\n",
    "    dependencies['chromadb'] = None\n",
    "    print(\"‚ùå ChromaDB not available\")\n",
    "\n",
    "try:\n",
    "    import plotly\n",
    "    dependencies['plotly'] = plotly.__version__\n",
    "    print(f\"‚úÖ Plotly: {plotly.__version__}\")\n",
    "except ImportError:\n",
    "    dependencies['plotly'] = None\n",
    "    print(\"‚ùå Plotly not available\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0ccfac9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize RAG Enhancement\n",
    "print(\"üß† Initializing RAG Enhancement...\")\n",
    "\n",
    "try:\n",
    "    from src.chatbot.rag_enhancer import SimpleRAGEnhancer\n",
    "    \n",
    "    # Initialize RAG enhancer\n",
    "    rag_enhancer = SimpleRAGEnhancer()\n",
    "    rag_status = rag_enhancer.get_rag_status()\n",
    "    \n",
    "    print(f\"‚úÖ RAG initialized successfully!\")\n",
    "    print(f\"üìä RAG Mode: {rag_status['rag_mode']}\")\n",
    "    print(f\"üîß Dependencies:\")\n",
    "    for dep, available in rag_status['dependencies_available'].items():\n",
    "        status = \"‚úÖ\" if available else \"‚ùå\"\n",
    "        print(f\"   {status} {dep}: {available}\")\n",
    "    \n",
    "    # Display RAG status\n",
    "    print(f\"\\nüìà Indexed Data:\")\n",
    "    print(f\"   CSV chunks: {rag_status['indexed_data']['csv_chunks']}\")\n",
    "    print(f\"   Conversation history: {rag_status['indexed_data']['conversation_history']}\")\n",
    "    \n",
    "except ImportError as e:\n",
    "    print(f\"‚ùå RAG Enhancement not available: {e}\")\n",
    "    rag_enhancer = None\n",
    "except Exception as e:\n",
    "    print(f\"‚ùå Error initializing RAG: {e}\")\n",
    "    rag_enhancer = None\n",
    "\n",
    "print(\"\\n\" + \"=\"*50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "161485f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create Sample Data for Testing\n",
    "print(\"üìä Creating sample data for RAG testing...\")\n",
    "\n",
    "try:\n",
    "    from data.create_sample_data import create_sample_sales_data, create_sample_customer_data\n",
    "    \n",
    "    # Create sample datasets\n",
    "    sales_df = create_sample_sales_data()\n",
    "    customer_df = create_sample_customer_data()\n",
    "    \n",
    "    print(f\"‚úÖ Sales data created: {sales_df.shape[0]} rows, {sales_df.shape[1]} columns\")\n",
    "    print(f\"‚úÖ Customer data created: {customer_df.shape[0]} rows, {customer_df.shape[1]} columns\")\n",
    "    \n",
    "    # Display sample data\n",
    "    print(\"\\nüìà Sales Data Sample:\")\n",
    "    display(sales_df.head())\n",
    "    \n",
    "    print(\"\\nüë• Customer Data Sample:\")\n",
    "    display(customer_df.head())\n",
    "    \n",
    "    # Index data for RAG if available\n",
    "    if rag_enhancer:\n",
    "        print(\"\\nüß† Indexing data for RAG...\")\n",
    "        rag_enhancer.index_csv_data(sales_df)\n",
    "        print(\"‚úÖ Sales data indexed for RAG retrieval\")\n",
    "        \n",
    "        # Show updated RAG status\n",
    "        updated_status = rag_enhancer.get_rag_status()\n",
    "        print(f\"üìä RAG Status after indexing:\")\n",
    "        print(f\"   CSV chunks: {updated_status['indexed_data']['csv_chunks']}\")\n",
    "    \n",
    "except Exception as e:\n",
    "    print(f\"‚ùå Error creating sample data: {e}\")\n",
    "    sales_df = None\n",
    "    customer_df = None\n",
    "\n",
    "print(\"\\n\" + \"=\"*50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d150ea6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# RAG vs Traditional Approach Comparison\n",
    "print(\"üîç Testing RAG vs Traditional Approach...\")\n",
    "\n",
    "if rag_enhancer and sales_df is not None:\n",
    "    # Test questions for comparison\n",
    "    test_questions = [\n",
    "        \"What's the total sales amount?\",  # Traditional\n",
    "        \"Analyze sales patterns and trends in the data\",  # RAG\n",
    "        \"Show me correlations between different variables\",  # RAG  \n",
    "        \"SELECT COUNT(*) FROM sales\",  # Traditional\n",
    "        \"Explain the relationship between product categories and sales performance\",  # RAG\n",
    "        \"Calculate the average order value\"  # Traditional\n",
    "    ]\n",
    "    \n",
    "    print(\"ü§î Testing question classification:\")\n",
    "    print(\"-\" * 40)\n",
    "    \n",
    "    for question in test_questions:\n",
    "        should_use_rag = rag_enhancer.should_use_rag(question)\n",
    "        approach = \"üß† RAG\" if should_use_rag else \"üìä Traditional\"\n",
    "        print(f\"{approach}: {question}\")\n",
    "    \n",
    "    print(\"\\n\" + \"=\"*50)\n",
    "    print(\"üß† RAG Retrieval Test:\")\n",
    "    print(\"-\" * 40)\n",
    "    \n",
    "    # Test RAG retrieval with analytical questions\n",
    "    analytical_queries = [\n",
    "        \"sales patterns\",\n",
    "        \"product performance\",\n",
    "        \"customer behavior\",\n",
    "        \"revenue trends\"\n",
    "    ]\n",
    "    \n",
    "    for query in analytical_queries:\n",
    "        relevant_docs = rag_enhancer.retrieve_relevant_data(query, \"csv\", top_k=2)\n",
    "        print(f\"Query: '{query}' ‚Üí Found {len(relevant_docs)} relevant chunks\")\n",
    "        \n",
    "        if relevant_docs:\n",
    "            for i, doc in enumerate(relevant_docs[:1]):  # Show first result only\n",
    "                print(f\"  üìÑ Chunk {i+1} (score: {doc.get('score', 'N/A')}):\")\n",
    "                content_preview = doc['content'][:200] + \"...\" if len(doc['content']) > 200 else doc['content']\n",
    "                print(f\"     {content_preview}\")\n",
    "                print()\n",
    "    \n",
    "else:\n",
    "    print(\"‚ùå RAG enhancer or sample data not available\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d95ab12f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Interactive RAG Demo\n",
    "print(\"üéÆ Interactive RAG-Enhanced Chatbot Demo\")\n",
    "\n",
    "def simple_llm_mock(query, context):\n",
    "    \"\"\"Mock LLM function for demonstration\"\"\"\n",
    "    if \"sales\" in query.lower():\n",
    "        return f\"Based on the data analysis: {query}\"\n",
    "    elif \"pattern\" in query.lower() or \"trend\" in query.lower():\n",
    "        return f\"Pattern analysis shows: {query}\"\n",
    "    elif \"correlation\" in query.lower():\n",
    "        return f\"Correlation analysis indicates: {query}\"\n",
    "    else:\n",
    "        return f\"Analysis result: {query}\"\n",
    "\n",
    "def demo_question(question):\n",
    "    \"\"\"Demo function to test a question with and without RAG\"\"\"\n",
    "    print(f\"\\n‚ùì Question: '{question}'\")\n",
    "    print(\"-\" * 60)\n",
    "    \n",
    "    if rag_enhancer:\n",
    "        # Test if RAG should be used\n",
    "        should_use_rag = rag_enhancer.should_use_rag(question)\n",
    "        print(f\"ü§î RAG Decision: {'Use RAG' if should_use_rag else 'Use Traditional'}\")\n",
    "        \n",
    "        if should_use_rag:\n",
    "            # Generate RAG-enhanced response\n",
    "            try:\n",
    "                rag_response = rag_enhancer.generate_rag_response(question, simple_llm_mock)\n",
    "                print(f\"üß† RAG Response: {rag_response}\")\n",
    "            except Exception as e:\n",
    "                print(f\"‚ùå RAG Error: {e}\")\n",
    "        else:\n",
    "            # Generate traditional response\n",
    "            traditional_response = simple_llm_mock(question, \"\")\n",
    "            print(f\"üìä Traditional Response: {traditional_response}\")\n",
    "    else:\n",
    "        print(\"‚ùå RAG not available - using traditional approach\")\n",
    "        print(f\"üìä Response: {simple_llm_mock(question, '')}\")\n",
    "\n",
    "# Demo questions\n",
    "demo_questions = [\n",
    "    \"What's the total sales in the dataset?\",\n",
    "    \"Analyze the sales patterns and identify trends\",\n",
    "    \"Show me correlations between product categories and revenue\",\n",
    "    \"Count the number of unique customers\",\n",
    "    \"Explain the relationship between time and sales performance\"\n",
    "]\n",
    "\n",
    "print(\"üöÄ Running demo with sample questions...\")\n",
    "for question in demo_questions:\n",
    "    demo_question(question)\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"‚úÖ Interactive demo complete!\")\n",
    "print(\"\\nüí° Try your own questions:\")\n",
    "print(\"   - Analytical questions will use RAG\")\n",
    "print(\"   - Simple queries will use traditional approach\")\n",
    "print(\"   - RAG provides context-aware responses\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6908fb61",
   "metadata": {},
   "source": [
    "## üéâ Demo Complete!\n",
    "\n",
    "### What we demonstrated:\n",
    "1. **RAG Enhancement Setup** - Automatic fallback to simple mode if dependencies missing\n",
    "2. **Data Indexing** - CSV data chunked and indexed for semantic retrieval\n",
    "3. **Smart Question Classification** - Automatic detection of when to use RAG vs traditional\n",
    "4. **Context-Aware Responses** - RAG provides relevant data context to improve answers\n",
    "5. **Graceful Degradation** - Works with or without advanced dependencies\n",
    "\n",
    "### Key Benefits of RAG:\n",
    "- **Better Context**: Responses include relevant data chunks from your datasets\n",
    "- **Improved Accuracy**: LLM has access to specific data points when answering\n",
    "- **Flexible**: Automatically chooses best approach based on question type\n",
    "- **Local**: Everything runs on your machine, no API calls needed\n",
    "\n",
    "### Next Steps:\n",
    "1. **Install Advanced Dependencies**: `pip install sentence-transformers chromadb`\n",
    "2. **Try the Web Interface**: `streamlit run local_demo.py`\n",
    "3. **Upload Your Own Data**: Test with your CSV files\n",
    "4. **Ask Analytical Questions**: Get insights from your data\n",
    "\n",
    "### Learn More:\n",
    "- Check out `local_demo.py` for the full web interface\n",
    "- Run `python demo.py` for a command-line demo\n",
    "- Explore the source code in `src/chatbot/rag_enhancer.py`"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
